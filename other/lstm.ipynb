{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6696abe3",
   "metadata": {},
   "source": [
    "[Долгая краткосрочная память](https://neerc.ifmo.ru/wiki/index.php?title=%D0%94%D0%BE%D0%BB%D0%B3%D0%B0%D1%8F_%D0%BA%D1%80%D0%B0%D1%82%D0%BA%D0%BE%D1%81%D1%80%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BF%D0%B0%D0%BC%D1%8F%D1%82%D1%8C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c5e352",
   "metadata": {},
   "source": [
    "**keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03ef8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.data_utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e888dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    \n",
    "    def recall(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234c0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем seed для обеспечения повторяемости результатов\n",
    "np.random.seed(42)\n",
    "\n",
    "# Указываем количество слов из частотного словаря, которое будет использоваться (отсортированы по частоте использования)\n",
    "max_features = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506c87c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_words` argument in `load_data` has been renamed `num_words`.\n"
     ]
    }
   ],
   "source": [
    "# Загружаем данные (датасет IMDB содержит 25000 рецензий на фильмы с правильным ответом для обучения и 25000 рецензий на фильмы с правильным ответом для тестирования)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a01c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем максимальную длину рецензий в словах, чтобы они все были одной длины\n",
    "maxlen = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b126d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем короткие рецензии пробелами, а длинные обрезаем\n",
    "X_train = pad_sequences(X_train, maxlen = maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b13f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем модель последовательной сети\n",
    "model = Sequential()\n",
    "# Добавляем слой для векторного представления слов (5000 слов, каждое представлено вектором из 32 чисел, отключаем входной сигнал с вероятностью 20% для предотвращения переобучения)\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(Dropout(0.2))\n",
    "# Добавляем слой долго-краткосрочной памяти (100 элементов для долговременного хранения информации, отключаем входной сигнал с вероятностью 20%, отключаем рекуррентный сигнал с вероятностью 20%)\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "# Добавляем полносвязный слой из 1 элемента для классификации, в качестве функции активации будем использовать сигмоидальную функцию\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Компилируем модель нейронной сети\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy', f1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4688d762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          160000    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 32)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               53200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b31aaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "391/391 [==============================] - 39s 96ms/step - loss: 0.4646 - accuracy: 0.7689 - f1: 0.7701 - val_loss: 0.3723 - val_accuracy: 0.8302 - val_f1: 0.8401\n",
      "Epoch 2/7\n",
      "391/391 [==============================] - 37s 96ms/step - loss: 0.3248 - accuracy: 0.8637 - f1: 0.8627 - val_loss: 0.3920 - val_accuracy: 0.8222 - val_f1: 0.8334\n",
      "Epoch 3/7\n",
      "391/391 [==============================] - 38s 98ms/step - loss: 0.3009 - accuracy: 0.8750 - f1: 0.8744 - val_loss: 0.3797 - val_accuracy: 0.8313 - val_f1: 0.8189\n",
      "Epoch 4/7\n",
      "391/391 [==============================] - 35s 90ms/step - loss: 0.2633 - accuracy: 0.8923 - f1: 0.8907 - val_loss: 0.3816 - val_accuracy: 0.8292 - val_f1: 0.8349\n",
      "Epoch 5/7\n",
      "391/391 [==============================] - 35s 90ms/step - loss: 0.2376 - accuracy: 0.9055 - f1: 0.9042 - val_loss: 0.4025 - val_accuracy: 0.8314 - val_f1: 0.8254\n",
      "Epoch 6/7\n",
      "391/391 [==============================] - 35s 89ms/step - loss: 0.2120 - accuracy: 0.9170 - f1: 0.9161 - val_loss: 0.4733 - val_accuracy: 0.8289 - val_f1: 0.8329\n",
      "Epoch 7/7\n",
      "391/391 [==============================] - 33s 84ms/step - loss: 0.1924 - accuracy: 0.9248 - f1: 0.9238 - val_loss: 0.5389 - val_accuracy: 0.8220 - val_f1: 0.8144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffe9f381c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучаем нейронную сеть (данные для обучения, ответы к данным для обучения, количество рецензий после анализа которого будут изменены веса, число эпох обучения, тестовые данные, показывать progress bar или нет)\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size = 64,\n",
    "    epochs = 7,\n",
    "    validation_data = (X_test, y_test),\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c70e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 8s 20ms/step - loss: 0.5389 - accuracy: 0.8220 - f1: 0.8144\n",
      "Точность на тестовых данных: 82.20%\n",
      "F1 на тестовых данных: 81.44%\n"
     ]
    }
   ],
   "source": [
    "# Проверяем качество обучения на тестовых данных (если есть данные, которые не участвовали в обучении, лучше использовать их, но в нашем случае таковых нет)\n",
    "scores = model.evaluate(X_test, y_test, batch_size = 64)\n",
    "\n",
    "print('Точность на тестовых данных: %.2f%%' % (scores[1] * 100))\n",
    "print('F1 на тестовых данных: %.2f%%' % (scores[2] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacdb8d8",
   "metadata": {},
   "source": [
    "**tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c94b6a5",
   "metadata": {},
   "source": [
    "[Tensorflow LSTM](https://www.educba.com/tensorflow-lstm/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54f19c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e19efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations related to the model\n",
    "extra_metric_param = ['accuracy']\n",
    "size_of_single_batch = 128\n",
    "output_of_dims = 15\n",
    "function_used_for_Loss= BinaryCrossentropy()\n",
    "length_of_maximum_sequence = 300\n",
    "distinct_words_number = 5000\n",
    "epochs_count = 5\n",
    "optimizer = Adam()\n",
    "split_for_validation = 0.20\n",
    "Mode_Verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc91fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution should be in eager mode, so disable it\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed02ab0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "# Data set should be loaded first\n",
    "(x_train, y_train), (test_for_X_coordinate, test_for_Y_coordinate) = imdb.load_data(num_words=distinct_words_number)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(test_for_X_coordinate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9efd9cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequences should have proper padding between them\n",
    "padded_inputs = pad_sequences(\n",
    "    x_train, \n",
    "    maxlen=length_of_maximum_sequence, \n",
    "    value = 0.0\n",
    ") # 0.0 because it corresponds with <PAD>\n",
    "\n",
    "padded_inputs_test = pad_sequences(\n",
    "    test_for_X_coordinate, \n",
    "    maxlen=length_of_maximum_sequence, \n",
    "    value = 0.0\n",
    ") # 0.0 because it corresponds with <PAD>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e67a9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keras model that will be used should be defined properly\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(distinct_words_number, output_of_dims, input_length=length_of_maximum_sequence))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Model is compiled\n",
    "model.compile(optimizer=optimizer, loss=BinaryCrossentropy(), metrics=extra_metric_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "174043aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 300, 15)           75000     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 10)                1040      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,051\n",
      "Trainable params: 76,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Providing brief summary about the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d586630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - ETA: 0s - loss: 0.4589 - acc: 0.8025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2332: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 13s 637us/sample - loss: 0.4589 - acc: 0.8025 - val_loss: 0.3648 - val_acc: 0.8544\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 13s 645us/sample - loss: 0.2985 - acc: 0.8867 - val_loss: 0.3164 - val_acc: 0.8724\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 13s 647us/sample - loss: 0.2394 - acc: 0.9123 - val_loss: 0.3140 - val_acc: 0.8746\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 13s 651us/sample - loss: 0.2101 - acc: 0.9259 - val_loss: 0.3094 - val_acc: 0.8732\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 13s 654us/sample - loss: 0.1832 - acc: 0.9381 - val_loss: 0.3485 - val_acc: 0.8660\n"
     ]
    }
   ],
   "source": [
    "# Model is being trained\n",
    "history = model.fit(\n",
    "    padded_inputs, \n",
    "    y_train, \n",
    "    batch_size=size_of_single_batch, \n",
    "    epochs=epochs_count, \n",
    "    verbose=Mode_Verbose, \n",
    "    validation_split=split_for_validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a5aec16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results of the final test in case of Loss: 0.36116048718452454 and the accuracy of model is : 0.8590400218963623\n"
     ]
    }
   ],
   "source": [
    "# Model should be tested after the completion of the training\n",
    "result_of_testing = model.evaluate(padded_inputs_test, test_for_Y_coordinate, verbose=False)\n",
    "\n",
    "print(f'Results of the final test in case of Loss: {result_of_testing[0]} and the accuracy of model is : {result_of_testing[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81104fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
